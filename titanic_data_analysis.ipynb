{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-07-02T17:09:36.832589Z","iopub.status.busy":"2022-07-02T17:09:36.832138Z","iopub.status.idle":"2022-07-02T17:09:36.871896Z","shell.execute_reply":"2022-07-02T17:09:36.87076Z","shell.execute_reply.started":"2022-07-02T17:09:36.8325Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:09:40.391924Z","iopub.status.busy":"2022-07-02T17:09:40.391528Z","iopub.status.idle":"2022-07-02T17:09:40.419822Z","shell.execute_reply":"2022-07-02T17:09:40.418676Z","shell.execute_reply.started":"2022-07-02T17:09:40.391893Z"},"trusted":true},"outputs":[],"source":["train = pd.read_csv('./input/train.csv')\n","test = pd.read_csv('./input/test.csv')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:09:45.697698Z","iopub.status.busy":"2022-07-02T17:09:45.697294Z","iopub.status.idle":"2022-07-02T17:09:45.701507Z","shell.execute_reply":"2022-07-02T17:09:45.700665Z","shell.execute_reply.started":"2022-07-02T17:09:45.697665Z"},"trusted":true},"outputs":[],"source":["train.isna().any()\n","#there are a lot of features that do not have the row information availabile. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:09:52.984479Z","iopub.status.busy":"2022-07-02T17:09:52.984086Z","iopub.status.idle":"2022-07-02T17:09:53.001296Z","shell.execute_reply":"2022-07-02T17:09:53.000206Z","shell.execute_reply.started":"2022-07-02T17:09:52.984446Z"},"trusted":true},"outputs":[],"source":["#we will fill in or IMPUTE the missing data. Before we do that, we need to pick a suitable method of imputation. \n","train['Age'] = train['Age'].fillna(train['Age'].mean())\n","train['Embarked'] = train['Embarked'].fillna(method=('ffill'))\n","test['Age'] = test['Age'].fillna(test['Age'].mean())\n","test['Embarked'] = test['Embarked'].fillna(method=('ffill'))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:09:58.827237Z","iopub.status.busy":"2022-07-02T17:09:58.826815Z","iopub.status.idle":"2022-07-02T17:09:58.837421Z","shell.execute_reply":"2022-07-02T17:09:58.836326Z","shell.execute_reply.started":"2022-07-02T17:09:58.827205Z"},"trusted":true},"outputs":[],"source":["train.isna().any()\n","#Because Cabin column has a lot of missing values, our imputation will not give us good results because it will introduce a lot of biases.\n","#So it is better to drop the column"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:10:06.679831Z","iopub.status.busy":"2022-07-02T17:10:06.679109Z","iopub.status.idle":"2022-07-02T17:10:06.684681Z","shell.execute_reply":"2022-07-02T17:10:06.683486Z","shell.execute_reply.started":"2022-07-02T17:10:06.679794Z"},"trusted":true},"outputs":[],"source":["#Now we want to find how much correlation these columns have on the Survival of the passenger.\n","#For this we can plot the data.\n","#For the categorical data like Sex, we can assign numerical value like 0 or 1\n","#We can also normalize the data\n","#most likely Ticket number is not correlated to the Survival of the passengers so we can drop this column as well.\n","#train.drop('Ticket',axis=1,inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:10:08.960512Z","iopub.status.busy":"2022-07-02T17:10:08.95955Z","iopub.status.idle":"2022-07-02T17:10:08.989163Z","shell.execute_reply":"2022-07-02T17:10:08.988067Z","shell.execute_reply.started":"2022-07-02T17:10:08.960471Z"},"trusted":true},"outputs":[],"source":["#PIVOTING FEATURES\n","#This should be done after we have taken care of the missing values\n","#We Pivot the features Pclass, Sex,and SibSp against the Survived to see the correlation\n","#Generally, this is suited for features that do not take too many values or are not continuous\n","\n","train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:10:11.204511Z","iopub.status.busy":"2022-07-02T17:10:11.203899Z","iopub.status.idle":"2022-07-02T17:10:11.218254Z","shell.execute_reply":"2022-07-02T17:10:11.217081Z","shell.execute_reply.started":"2022-07-02T17:10:11.204463Z"},"trusted":true},"outputs":[],"source":["train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:10:13.35842Z","iopub.status.busy":"2022-07-02T17:10:13.35746Z","iopub.status.idle":"2022-07-02T17:10:13.373085Z","shell.execute_reply":"2022-07-02T17:10:13.371903Z","shell.execute_reply.started":"2022-07-02T17:10:13.358383Z"},"trusted":true},"outputs":[],"source":["train[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:10:15.585133Z","iopub.status.busy":"2022-07-02T17:10:15.584477Z","iopub.status.idle":"2022-07-02T17:10:16.663282Z","shell.execute_reply":"2022-07-02T17:10:16.662042Z","shell.execute_reply.started":"2022-07-02T17:10:15.585097Z"},"trusted":true},"outputs":[],"source":["#For features like age and fare, we may want to use some visual ways to find the correlation\n","survival_with_age = sns.FacetGrid(train, col='Survived')\n","survival_with_age.map(plt.hist, 'Age', bins=20)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:10:17.746961Z","iopub.status.busy":"2022-07-02T17:10:17.746037Z","iopub.status.idle":"2022-07-02T17:10:18.909984Z","shell.execute_reply":"2022-07-02T17:10:18.908843Z","shell.execute_reply.started":"2022-07-02T17:10:17.746918Z"},"trusted":true},"outputs":[],"source":["survival_with_age_in_fixed_PClass = sns.FacetGrid(train, col='Survived', row='Pclass', size=2.5, aspect=1.6)\n","survival_with_age_in_fixed_PClass.map(plt.hist, 'Age', alpha=1, bins=10)\n","survival_with_age_in_fixed_PClass.add_legend()\n","#This shows that most people in PClass = 3 did not survive, and most people in PClass = 1 survived"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:10:21.863874Z","iopub.status.busy":"2022-07-02T17:10:21.863447Z","iopub.status.idle":"2022-07-02T17:10:23.134362Z","shell.execute_reply":"2022-07-02T17:10:23.133291Z","shell.execute_reply.started":"2022-07-02T17:10:21.863839Z"},"trusted":true},"outputs":[],"source":["#We may also find correlation between PClass and port of Embarkment to see if there is a correlation\n","#This is an example of observing categorical and non-categorical features together.\n","#Here we have PClass and Survived as non-categorical features, so they can be represented as points in the plot.\n","#Sex is a categorical feature so it will be plotted as a legend\n","survival_with_sex_in_pclass = sns.FacetGrid(train, row='Embarked', size=2.2, aspect=1.6)\n","survival_with_sex_in_pclass.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='bright')\n","survival_with_sex_in_pclass.add_legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:10:24.60184Z","iopub.status.busy":"2022-07-02T17:10:24.601406Z","iopub.status.idle":"2022-07-02T17:10:25.97697Z","shell.execute_reply":"2022-07-02T17:10:25.975657Z","shell.execute_reply.started":"2022-07-02T17:10:24.601806Z"},"trusted":true},"outputs":[],"source":["#For a non-categorical feature like Fare, for which there are a variety of values, and likely no specific pattern\n","#We can band together ranges of Fare and extract information based on that\n","banding_fare = sns.FacetGrid(train, row='Embarked', col='Survived', size=2.2, aspect=1.6)\n","banding_fare.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=95, capsize=0.1)\n","banding_fare.add_legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:10:27.336913Z","iopub.status.busy":"2022-07-02T17:10:27.336521Z","iopub.status.idle":"2022-07-02T17:10:27.342538Z","shell.execute_reply":"2022-07-02T17:10:27.341709Z","shell.execute_reply.started":"2022-07-02T17:10:27.336882Z"},"trusted":true},"outputs":[],"source":["#Now we will extract the titles of names as they may be related to survival rate, while names of people may not be\n","#We'll have to extract the titles from the names in both train and test data\n","all_data = [train,test]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:10:30.044535Z","iopub.status.busy":"2022-07-02T17:10:30.043678Z","iopub.status.idle":"2022-07-02T17:10:30.07716Z","shell.execute_reply":"2022-07-02T17:10:30.076026Z","shell.execute_reply.started":"2022-07-02T17:10:30.044499Z"},"trusted":true},"outputs":[],"source":["#crosstab gets frequency count of columns\n","#Titles are identifird by capital character, small letter, and then a period. \n","#This is what will be identified by the str.extract() function\n","for column in all_data:\n","    column['Title'] = column.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n","\n","pd.crosstab(train['Title'], train['Sex'])\n","#And now we have the frequency of different titles. We find that some titles are more common than others.\n","#Master,Mr, Miss, and Mrs are more common than Capt, Col, Don etc.\n","# We can also Mme and Mlle are titles for Miss in French. So let's combine these under 'Miss'\n","# The we can put all the less frequesnt titles as 'Rare'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:10:32.085724Z","iopub.status.busy":"2022-07-02T17:10:32.084904Z","iopub.status.idle":"2022-07-02T17:10:32.101414Z","shell.execute_reply":"2022-07-02T17:10:32.100287Z","shell.execute_reply.started":"2022-07-02T17:10:32.085678Z"},"trusted":true},"outputs":[],"source":["for columns in all_data:#The first line replaces the less frequent titles with 'Rare'\n","    \n","    columns['Title'] = columns['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n","#the next 3 lines fix the French titles back to English\n","    columns['Title'] = columns['Title'].replace('Mlle', 'Miss')\n","    columns['Title'] = columns['Title'].replace('Ms', 'Miss')\n","    columns['Title'] = columns['Title'].replace('Mme', 'Mrs')\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:10:34.093295Z","iopub.status.busy":"2022-07-02T17:10:34.092903Z","iopub.status.idle":"2022-07-02T17:10:34.112554Z","shell.execute_reply":"2022-07-02T17:10:34.111774Z","shell.execute_reply.started":"2022-07-02T17:10:34.093263Z"},"trusted":true},"outputs":[],"source":["#Now we can check the survival rate based on title, only for the training data though\n","train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\n","#We can see that Miss and Mrs titles had a higher survival rate (probably because females survived more in general)\n","#Mrs have higher survival rate than Miss, Master had higher survival rate than Mr. \n","#Now we can drop the names column\n","#train = train.drop(['Name'], axis=1)\n","#train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:10:36.306862Z","iopub.status.busy":"2022-07-02T17:10:36.306423Z","iopub.status.idle":"2022-07-02T17:10:36.315858Z","shell.execute_reply":"2022-07-02T17:10:36.314721Z","shell.execute_reply.started":"2022-07-02T17:10:36.306828Z"},"trusted":true},"outputs":[],"source":["#Now we can do 2 more things: COnvert the categorical data to numerical by assigning a number to each category\n","#For example Male and Female can be 0 and 1 respectively\n","#This can be done on columns 'Sex', 'PClass', and 'Embarked'\n","for columns in all_data:\n","    columns['Sex'] = columns['Sex'].map( {'male':0, 'female':1} ).astype(int)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:10:41.179098Z","iopub.status.busy":"2022-07-02T17:10:41.178669Z","iopub.status.idle":"2022-07-02T17:10:41.188898Z","shell.execute_reply":"2022-07-02T17:10:41.187705Z","shell.execute_reply.started":"2022-07-02T17:10:41.179058Z"},"trusted":true},"outputs":[],"source":["for columns in all_data:\n","    columns['Embarked'] = columns['Embarked'].map( {'C':1, 'Q':2, 'S':3} ).astype(int)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:10:43.83974Z","iopub.status.busy":"2022-07-02T17:10:43.83888Z","iopub.status.idle":"2022-07-02T17:10:43.863144Z","shell.execute_reply":"2022-07-02T17:10:43.862084Z","shell.execute_reply.started":"2022-07-02T17:10:43.839697Z"},"trusted":true},"outputs":[],"source":["all_data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:10:46.313218Z","iopub.status.busy":"2022-07-02T17:10:46.312788Z","iopub.status.idle":"2022-07-02T17:10:46.318462Z","shell.execute_reply":"2022-07-02T17:10:46.317683Z","shell.execute_reply.started":"2022-07-02T17:10:46.313181Z"},"trusted":true},"outputs":[],"source":["#Looking back, the way we completed the Age feature my using the highest mean of Age to fill the NA values, may not be the best way to complete this feature\n","#A better way would be to see how other features relate to a given Age. For example, If feature Sex=female, Title=Miss, perhaps the age should be less than 18\n","#But our methodof filling the Age with overall mean Age in the column may have given us incorrect data.\n","#To implement the method mentioned, refer \"https://www.kaggle.com/code/startupsci/titanic-data-science-solutions\"\n","#for dataset in combine:\n"," #   for i in range(0, 2):\n","  #      for j in range(0, 3):\n","   #         guess_df = dataset[(dataset['Sex'] == i) & \\\n","    #                              (dataset['Pclass'] == j+1)]['Age'].dropna()\n","#\n"," #           # age_mean = guess_df.mean()\n","  #          # age_std = guess_df.std()\n","   #         # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n","#\n"," #           age_guess = guess_df.median()\n","#\n","  #          # Convert random age float to nearest .5 age\n"," #           guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n"," #           \n","  #  for i in range(0, 2):\n","   #     for j in range(0, 3):\n","    #        dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n","     #               'Age'] = guess_ages[i,j]\n","#\n"," #   dataset['Age'] = dataset['Age'].astype(int)\n","#\n","#train_df.head()\n","#from the above chunk of code, just remove the first # mark."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:10:48.141721Z","iopub.status.busy":"2022-07-02T17:10:48.141311Z","iopub.status.idle":"2022-07-02T17:10:48.173663Z","shell.execute_reply":"2022-07-02T17:10:48.172587Z","shell.execute_reply.started":"2022-07-02T17:10:48.141685Z"},"trusted":true},"outputs":[],"source":["#Now we will band the ages together as this is a continuous feature\n","#The number 5 in cut() determines the number of bands that age will be cut into\n","train['AgeBand'] = pd.cut(train['Age'], 5)\n","train[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:10:49.935132Z","iopub.status.busy":"2022-07-02T17:10:49.934749Z","iopub.status.idle":"2022-07-02T17:10:49.966042Z","shell.execute_reply":"2022-07-02T17:10:49.964961Z","shell.execute_reply.started":"2022-07-02T17:10:49.935099Z"},"trusted":true},"outputs":[],"source":["#We can create a new feature called Ageband and store the age information there.\n","#We will assign the band index to Age and store the corresponding range in the new feature\n","for columns in all_data:    \n","    columns.loc[ columns['Age'] <= 16, 'Age'] = 0\n","    columns.loc[(columns['Age'] > 16) & (columns['Age'] <= 32), 'Age'] = 1\n","    columns.loc[(columns['Age'] > 32) & (columns['Age'] <= 48), 'Age'] = 2\n","    columns.loc[(columns['Age'] > 48) & (columns['Age'] <= 64), 'Age'] = 3\n","    columns.loc[ columns['Age'] > 64, 'Age']\n","train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:10:51.796182Z","iopub.status.busy":"2022-07-02T17:10:51.795405Z","iopub.status.idle":"2022-07-02T17:10:51.81684Z","shell.execute_reply":"2022-07-02T17:10:51.815748Z","shell.execute_reply.started":"2022-07-02T17:10:51.796127Z"},"trusted":true},"outputs":[],"source":["#Similarly, we can band the Fare  feature as well and redefine a new feature to store the band information\n","train['FareBand'] = pd.cut(train['Fare'], 4)\n","train[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:10:53.745826Z","iopub.status.busy":"2022-07-02T17:10:53.745432Z","iopub.status.idle":"2022-07-02T17:10:53.783919Z","shell.execute_reply":"2022-07-02T17:10:53.782898Z","shell.execute_reply.started":"2022-07-02T17:10:53.745794Z"},"trusted":true},"outputs":[],"source":["for columns in all_data:    \n","    columns.loc[ columns['Fare'] <= 128.082, 'Fare'] = 0\n","    columns.loc[(columns['Fare'] > 128.082) & (columns['Fare'] <= 256.165), 'Fare'] = 1\n","    columns.loc[(columns['Fare'] > 256.165) & (columns['Fare'] <= 384.247), 'Fare'] = 2\n","    columns.loc[columns['Fare'] > 384.247, 'Fare'] = 3\n","    \n","all_data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:10:55.578083Z","iopub.status.busy":"2022-07-02T17:10:55.576841Z","iopub.status.idle":"2022-07-02T17:10:55.582761Z","shell.execute_reply":"2022-07-02T17:10:55.581861Z","shell.execute_reply.started":"2022-07-02T17:10:55.578033Z"},"trusted":true},"outputs":[],"source":["#Now we can drop the features we do not need like Names, Ticket, PassangerID,Ageband, Fareband,Cabin (has lot of missing values) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:10:57.45425Z","iopub.status.busy":"2022-07-02T17:10:57.453666Z","iopub.status.idle":"2022-07-02T17:10:57.459441Z","shell.execute_reply":"2022-07-02T17:10:57.458679Z","shell.execute_reply.started":"2022-07-02T17:10:57.454217Z"},"trusted":true},"outputs":[],"source":["train.drop('Cabin',axis=1,inplace=True)\n","train.drop('Name',axis=1,inplace=True)\n","train.drop('PassengerId',axis=1,inplace=True)\n","train.drop('Ticket',axis=1,inplace=True)\n","train.drop('FareBand',axis=1,inplace=True)\n","train.drop('AgeBand',axis=1,inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:02.722206Z","iopub.status.busy":"2022-07-02T17:11:02.721103Z","iopub.status.idle":"2022-07-02T17:11:02.741986Z","shell.execute_reply":"2022-07-02T17:11:02.741122Z","shell.execute_reply.started":"2022-07-02T17:11:02.722169Z"},"trusted":true},"outputs":[],"source":["train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:03.623014Z","iopub.status.busy":"2022-07-02T17:11:03.622381Z","iopub.status.idle":"2022-07-02T17:11:03.64034Z","shell.execute_reply":"2022-07-02T17:11:03.639235Z","shell.execute_reply.started":"2022-07-02T17:11:03.622966Z"},"trusted":true},"outputs":[],"source":["#What we are trying to achieve here is a dataset with numerical values that are between 0 to 4. The last feature we want to modify is the title.\n","#It is still categorical so let's make it numerical like we did with 'Embarked' and 'Sex'\n","#Step 1 is to check the correlation with survival\n","train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean().sort_values(by='Survived', ascending=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:04.469831Z","iopub.status.busy":"2022-07-02T17:11:04.469415Z","iopub.status.idle":"2022-07-02T17:11:04.478633Z","shell.execute_reply":"2022-07-02T17:11:04.477517Z","shell.execute_reply.started":"2022-07-02T17:11:04.469796Z"},"trusted":true},"outputs":[],"source":["#Step 2 is to reassign\n","for columns in all_data:\n","    columns['Title'] = columns['Title'].map( {'Master':0, 'Miss':1, 'Mr':2,'Mrs':3,'Rare':4} ).astype(int)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:05.308745Z","iopub.status.busy":"2022-07-02T17:11:05.30831Z","iopub.status.idle":"2022-07-02T17:11:05.331049Z","shell.execute_reply":"2022-07-02T17:11:05.330289Z","shell.execute_reply.started":"2022-07-02T17:11:05.308709Z"},"trusted":true},"outputs":[],"source":["all_data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:06.146027Z","iopub.status.busy":"2022-07-02T17:11:06.144836Z","iopub.status.idle":"2022-07-02T17:11:06.150624Z","shell.execute_reply":"2022-07-02T17:11:06.149755Z","shell.execute_reply.started":"2022-07-02T17:11:06.145976Z"},"trusted":true},"outputs":[],"source":["#Let's also drop the unwanted features from test data and then see what we have\n","#Remember that the bands were only created for train data because that was where we had survival rate available\n","\n","test.drop('Name',axis=1,inplace=True)\n","test.drop('PassengerId',axis=1,inplace=True)\n","test.drop('Cabin',axis=1,inplace=True)\n","test.drop('Ticket',axis=1,inplace=True)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:12.280597Z","iopub.status.busy":"2022-07-02T17:11:12.280013Z","iopub.status.idle":"2022-07-02T17:11:12.299846Z","shell.execute_reply":"2022-07-02T17:11:12.298767Z","shell.execute_reply.started":"2022-07-02T17:11:12.280567Z"},"trusted":true},"outputs":[],"source":["test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:13.126294Z","iopub.status.busy":"2022-07-02T17:11:13.125918Z","iopub.status.idle":"2022-07-02T17:11:13.147512Z","shell.execute_reply":"2022-07-02T17:11:13.146206Z","shell.execute_reply.started":"2022-07-02T17:11:13.126263Z"},"trusted":true},"outputs":[],"source":["#The last and final thing we will do is learn how to create a new column by extrapolating data in multiple columns and how it impacts the result (survival rate) \n","#The first new feature we will create is FamilySize by combining Parch and SibSp\n","for columns in train:\n","    train['FamilySize'] = train['SibSp'] + train['Parch'] + 1\n","\n","train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n","# We see that intermediate family size had better survival rate\n","for columns in test:\n","    test['FamilySize'] = test['SibSp'] + test['Parch'] + 1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:13.95685Z","iopub.status.busy":"2022-07-02T17:11:13.955792Z","iopub.status.idle":"2022-07-02T17:11:13.961104Z","shell.execute_reply":"2022-07-02T17:11:13.960084Z","shell.execute_reply.started":"2022-07-02T17:11:13.95681Z"},"trusted":true},"outputs":[],"source":["#Another way to look at this data is to see if the passenger was traveling alone or not"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:19.997198Z","iopub.status.busy":"2022-07-02T17:11:19.996848Z","iopub.status.idle":"2022-07-02T17:11:20.016826Z","shell.execute_reply":"2022-07-02T17:11:20.01593Z","shell.execute_reply.started":"2022-07-02T17:11:19.99717Z"},"trusted":true},"outputs":[],"source":["#Let's now compare if Survival depends on Family size\n","train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:20.776953Z","iopub.status.busy":"2022-07-02T17:11:20.776202Z","iopub.status.idle":"2022-07-02T17:11:20.782274Z","shell.execute_reply":"2022-07-02T17:11:20.781259Z","shell.execute_reply.started":"2022-07-02T17:11:20.776901Z"},"trusted":true},"outputs":[],"source":["#Because family size takes values from 0 to 11, we want to have it stay between 0 to 4, like other columns.\n","#SO we will simply consider whether the person was alone or not and that feature can take values 0 or 1\n","#So let's create this new feature "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:21.678762Z","iopub.status.busy":"2022-07-02T17:11:21.678375Z","iopub.status.idle":"2022-07-02T17:11:21.695595Z","shell.execute_reply":"2022-07-02T17:11:21.694528Z","shell.execute_reply.started":"2022-07-02T17:11:21.678729Z"},"trusted":true},"outputs":[],"source":["for column in all_data:\n","    column['IsAlone'] = 0\n","    column.loc[column['FamilySize'] == 1, 'IsAlone'] = 1\n","\n","train[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:22.49268Z","iopub.status.busy":"2022-07-02T17:11:22.491846Z","iopub.status.idle":"2022-07-02T17:11:22.511014Z","shell.execute_reply":"2022-07-02T17:11:22.510283Z","shell.execute_reply.started":"2022-07-02T17:11:22.49264Z"},"trusted":true},"outputs":[],"source":["all_data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:25.352762Z","iopub.status.busy":"2022-07-02T17:11:25.352201Z","iopub.status.idle":"2022-07-02T17:11:25.358392Z","shell.execute_reply":"2022-07-02T17:11:25.357502Z","shell.execute_reply.started":"2022-07-02T17:11:25.352732Z"},"trusted":true},"outputs":[],"source":["#Now we can drop the family size, sibsp and parch columns from both test and train data\n","test.drop('SibSp',axis=1,inplace=True)\n","test.drop('Parch',axis=1,inplace=True)\n","test.drop('FamilySize',axis=1,inplace=True)\n","train.drop('SibSp',axis=1,inplace=True)\n","train.drop('Parch',axis=1,inplace=True)\n","train.drop('FamilySize',axis=1,inplace=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:34.42076Z","iopub.status.busy":"2022-07-02T17:11:34.420176Z","iopub.status.idle":"2022-07-02T17:11:34.441205Z","shell.execute_reply":"2022-07-02T17:11:34.440187Z","shell.execute_reply.started":"2022-07-02T17:11:34.420728Z"},"trusted":true},"outputs":[],"source":["train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:36.328979Z","iopub.status.busy":"2022-07-02T17:11:36.328565Z","iopub.status.idle":"2022-07-02T17:11:36.347328Z","shell.execute_reply":"2022-07-02T17:11:36.346274Z","shell.execute_reply.started":"2022-07-02T17:11:36.328944Z"},"trusted":true},"outputs":[],"source":["test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:38.444918Z","iopub.status.busy":"2022-07-02T17:11:38.444516Z","iopub.status.idle":"2022-07-02T17:11:38.448791Z","shell.execute_reply":"2022-07-02T17:11:38.447989Z","shell.execute_reply.started":"2022-07-02T17:11:38.444886Z"},"trusted":true},"outputs":[],"source":["#Now that we have clean, normalized training data, we can build a model, train it, and test it out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:39.467351Z","iopub.status.busy":"2022-07-02T17:11:39.466679Z","iopub.status.idle":"2022-07-02T17:11:39.475931Z","shell.execute_reply":"2022-07-02T17:11:39.474829Z","shell.execute_reply.started":"2022-07-02T17:11:39.467316Z"},"trusted":true},"outputs":[],"source":["######Prepare the data#######\n","X_train = train.drop(\"Survived\", axis=1)\n","Y_train = train[\"Survived\"]\n","X_test  = test\n","X_train.shape, Y_train.shape, X_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:40.28669Z","iopub.status.busy":"2022-07-02T17:11:40.286287Z","iopub.status.idle":"2022-07-02T17:11:40.297471Z","shell.execute_reply":"2022-07-02T17:11:40.296512Z","shell.execute_reply.started":"2022-07-02T17:11:40.286655Z"},"trusted":true},"outputs":[],"source":["test.isna().any()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:42.280025Z","iopub.status.busy":"2022-07-02T17:11:42.279042Z","iopub.status.idle":"2022-07-02T17:11:42.286249Z","shell.execute_reply":"2022-07-02T17:11:42.285118Z","shell.execute_reply.started":"2022-07-02T17:11:42.279988Z"},"trusted":true},"outputs":[],"source":["test['Fare'] = train['Fare'].fillna(train['Fare'].mean())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:42.982226Z","iopub.status.busy":"2022-07-02T17:11:42.98143Z","iopub.status.idle":"2022-07-02T17:11:43.086321Z","shell.execute_reply":"2022-07-02T17:11:43.085206Z","shell.execute_reply.started":"2022-07-02T17:11:42.982182Z"},"trusted":true},"outputs":[],"source":["############  LINEAR MODEL ---- Logistic Regression Model#########\n","from sklearn.linear_model import LogisticRegression\n","model = LogisticRegression()\n","model.fit(X_train, Y_train)\n","predict = model.predict(X_test)\n","check_logreg = round(model.score(X_train, Y_train) * 100, 2)\n","check_logreg"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:43.865212Z","iopub.status.busy":"2022-07-02T17:11:43.864792Z","iopub.status.idle":"2022-07-02T17:11:43.882569Z","shell.execute_reply":"2022-07-02T17:11:43.881766Z","shell.execute_reply.started":"2022-07-02T17:11:43.865178Z"},"trusted":true},"outputs":[],"source":["#coef_ contain the coefficients for the prediction of each of the targets. It is also the same as if you trained a model to predict each of the targets separately\n","#coef_ will give us how much correlation is between each feature and the output prediction i.e. survival\n","correlation = pd.DataFrame(train.columns.delete(0))\n","correlation.columns = ['Feature']\n","correlation[\"Correlation\"] = pd.Series(model.coef_[0])\n","\n","correlation.sort_values(by='Correlation', ascending=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:46.021696Z","iopub.status.busy":"2022-07-02T17:11:46.021015Z","iopub.status.idle":"2022-07-02T17:11:46.036103Z","shell.execute_reply":"2022-07-02T17:11:46.034911Z","shell.execute_reply.started":"2022-07-02T17:11:46.02166Z"},"trusted":true},"outputs":[],"source":["############  LINEAR MODEL ---- Stochastic Gradient Descent Model   ####################\n","from sklearn.linear_model import SGDClassifier\n","model = SGDClassifier()\n","model.fit(X_train, Y_train)\n","Y_pred = model.predict(X_test)\n","check_sgd = round(model.score(X_train, Y_train) * 100, 2)\n","check_sgd"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:46.797432Z","iopub.status.busy":"2022-07-02T17:11:46.796735Z","iopub.status.idle":"2022-07-02T17:11:46.814022Z","shell.execute_reply":"2022-07-02T17:11:46.812367Z","shell.execute_reply.started":"2022-07-02T17:11:46.797395Z"},"trusted":true},"outputs":[],"source":["############# LINEAR MODEL : PERCEPTRON ############\n","from sklearn.linear_model import Perceptron\n","model = Perceptron()\n","model.fit(X_train, Y_train)\n","Y_pred = model.predict(X_test)\n","check_percp = round(model.score(X_train, Y_train) * 100, 2)\n","check_percp\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:48.499198Z","iopub.status.busy":"2022-07-02T17:11:48.498443Z","iopub.status.idle":"2022-07-02T17:11:48.941706Z","shell.execute_reply":"2022-07-02T17:11:48.940667Z","shell.execute_reply.started":"2022-07-02T17:11:48.499157Z"},"trusted":true},"outputs":[],"source":["############  ENSAMBLE MODEL ---- Random Forest ##################\n","from sklearn.ensemble import RandomForestRegressor\n","model = RandomForestRegressor(n_estimators=150)\n","model.fit(X_train, Y_train)\n","Y_pred = model.predict(X_test)\n","model.score(X_train, Y_train)\n","check_rf = round(model.score(X_train, Y_train) * 100, 2)\n","check_rf"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:19:58.586517Z","iopub.status.busy":"2022-07-02T17:19:58.586126Z","iopub.status.idle":"2022-07-02T17:19:58.604427Z","shell.execute_reply":"2022-07-02T17:19:58.603648Z","shell.execute_reply.started":"2022-07-02T17:19:58.586486Z"},"trusted":true},"outputs":[],"source":["############ Decision Tree #############\n","from sklearn.tree import DecisionTreeClassifier\n","model = DecisionTreeClassifier()\n","model.fit(X_train, Y_train)\n","Y_pred = model.predict(X_test)\n","check_tree = round(model.score(X_train, Y_train) * 100, 2)\n","check_tree\n","df_preds = pd.DataFrame({\"PassengerIndex\":list(range(1,len(Y_pred)+1)),\"Label\":Y_pred})\n","df_preds.to_csv(\"result.csv\",index=False,header=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:52.496398Z","iopub.status.busy":"2022-07-02T17:11:52.495998Z","iopub.status.idle":"2022-07-02T17:11:52.576467Z","shell.execute_reply":"2022-07-02T17:11:52.575599Z","shell.execute_reply.started":"2022-07-02T17:11:52.496367Z"},"trusted":true},"outputs":[],"source":["######## Support Vector Machine #########\n","######## This works great for small datasets, where decision is made based on yes or no type of answer######\n","#Basically, the code tries to draw a plane separating two types of data \n","# It tries to get as many points on the right side as possible by optimizing the plane\n","# The plane can be in a hyper space but it is easy to visualize in 3D space.\n","#The plane is optimized in such a way that it is far enough from the nearest points on either sides of the plane\n","# The sum of normals from the nearest point on either sides of the plane to the plane itself is called margin\n","# The points themselves are called SUPPORTING VECTORS\n","# It is a supervized learning algorithm because the training data must have the result already in it\n","# If the data is such that it cannot be easily separated, for example, points on a 2D plane that are somewhat concentric\n","## then it may be useful to build an additional feature to increase the dimensionality of the space such that the new feature offsets these points \n","### in that case, the points can be separated somewhat through a plane normal to that new feature\n","\n","from sklearn.svm import SVC\n","model = SVC()\n","model.fit(X_train, Y_train)\n","Y_pred = model.predict(X_test)\n","check_svm = round(model.score(X_train, Y_train) * 100, 2)\n","check_svm"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:54.142638Z","iopub.status.busy":"2022-07-02T17:11:54.141987Z","iopub.status.idle":"2022-07-02T17:11:54.196857Z","shell.execute_reply":"2022-07-02T17:11:54.195709Z","shell.execute_reply.started":"2022-07-02T17:11:54.142593Z"},"trusted":true},"outputs":[],"source":["######### LINEAR SVC ##########\n","from sklearn.svm import LinearSVC\n","model = LinearSVC()\n","model.fit(X_train, Y_train)\n","Y_pred = model.predict(X_test)\n","check_svc = round(model.score(X_train, Y_train) * 100, 2)\n","check_svc"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:55.723915Z","iopub.status.busy":"2022-07-02T17:11:55.723335Z","iopub.status.idle":"2022-07-02T17:11:55.793765Z","shell.execute_reply":"2022-07-02T17:11:55.792917Z","shell.execute_reply.started":"2022-07-02T17:11:55.723875Z"},"trusted":true},"outputs":[],"source":["############ K-Nearest Neighbor ########\n","# Calssifies data\n","#It takes the prediction data row and searches the entire training set to check which are the closest data points\n","# K means how many nearest neighboring datapoints we are going to compare the test or prediction data to \n","# K should be optimized: too low and you will have noise, too high and you'll outvote the category with few data points\n","from sklearn.neighbors import KNeighborsClassifier\n","model = KNeighborsClassifier(n_neighbors = 6)\n","model.fit(X_train, Y_train)\n","Y_pred = model.predict(X_test)\n","check_knn = round(model.score(X_train, Y_train) * 100, 2)\n","check_knn"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:11:57.891648Z","iopub.status.busy":"2022-07-02T17:11:57.890278Z","iopub.status.idle":"2022-07-02T17:11:57.913167Z","shell.execute_reply":"2022-07-02T17:11:57.912407Z","shell.execute_reply.started":"2022-07-02T17:11:57.891578Z"},"trusted":true},"outputs":[],"source":["#### NAIVE BAYES ########\n","# The Multinomial Naive Bayes Classifier \n","# Another classification problem (yes or no),\n","# Multiplication of probabilities of features giving us one result versus another\n","#This method does not work directly if there is a feature with probability = 0\n","#To make it work in that case, we should add a \"black box\" to each feature\n","from sklearn.naive_bayes import MultinomialNB\n","model = MultinomialNB()\n","model.fit(X_train,Y_train)\n","Y_predict = model.predict(X_test)\n","check_nb = round(model.score(X_train, Y_train) * 100, 2)\n","check_nb"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T17:16:01.354454Z","iopub.status.busy":"2022-07-02T17:16:01.353511Z","iopub.status.idle":"2022-07-02T17:16:01.369752Z","shell.execute_reply":"2022-07-02T17:16:01.368457Z","shell.execute_reply.started":"2022-07-02T17:16:01.354411Z"},"trusted":true},"outputs":[],"source":["models = pd.DataFrame({\n","    'Model': ['Logistic Regression', 'Stochastic Gradient Descent', 'Perceptron', \n","              'Random Forest', 'Decision Tree', 'Support Vector Machine', \n","              'Linear Support Vector Machine', 'K Nearest Neighbor', \n","              'Naive Bayes'],\n","    'Score': [check_logreg, check_sgd, check_percp, \n","              check_rf, check_tree, check_svm, \n","              check_svc, check_knn, check_nb]})\n","models.sort_values(by='Score', ascending=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Decision tree gives the highest score. The result.csv file contains the output predictions from this model"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
